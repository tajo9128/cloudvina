{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ§¬ BioDockify AI: ChemBERTa Training Pipeline\n",
                "\n",
                "This notebook trains AI models for drug discovery using the **ChemBERTa** architecture.\n",
                "It is part of the **ai.biodockify.com** zero-cost platform.\n",
                "\n",
                "**Steps:**\n",
                "1. Install Dependencies\n",
                "2. Download Data from ChEMBL (e.g., Alzheimer's, Cancer)\n",
                "3. Train Model (Free GPU)\n",
                "4. Upload to Hugging Face"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install Dependencies\n",
                "!pip install simpletransformers chembl_webresource_client pandas scikit-learn transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Login to Hugging Face (For Uploading)\n",
                "from huggingface_hub import notebook_login\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 3: Download Training Data (Alzheimer's - BACE1)\n",
                "import pandas as pd\n",
                "from chembl_webresource_client.new_client import new_client\n",
                "\n",
                "def download_chembl_data(target_chembl_id, output_name):\n",
                "    print(f\"Downloading {output_name} ({target_chembl_id})...\")\n",
                "    activities = new_client.activity\n",
                "    res = activities.filter(target_chembl_id=target_chembl_id).filter(standard_type=\"IC50\")\n",
                "    \n",
                "    data = []\n",
                "    for act in res:\n",
                "        if act['standard_value'] and act['canonical_smiles']:\n",
                "            data.append({\n",
                "                'smiles': act['canonical_smiles'],\n",
                "                'labels': 1 if float(act['standard_value']) < 1000 else 0  # Active < 1000nM\n",
                "            })\n",
                "            \n",
                "    df = pd.DataFrame(data)\n",
                "    df = df.drop_duplicates(subset=['smiles'])\n",
                "    return df\n",
                "\n",
                "# BACE1 for Alzheimer's\n",
                "df = download_chembl_data(\"CHEMBL4822\", \"Alzheimers\")\n",
                "print(f\"Downloaded {len(df)} compounds\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 4: Train ChemBERTa Model\n",
                "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
                "import sklearn\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "train_df, eval_df = train_test_split(df, test_size=0.2)\n",
                "\n",
                "model_args = ClassificationArgs(\n",
                "    num_train_epochs=3,\n",
                "    overwrite_output_dir=True,\n",
                "    use_early_stopping=True,\n",
                "    save_steps=-1,\n",
                "    train_batch_size=32\n",
                ")\n",
                "\n",
                "model = ClassificationModel(\n",
                "    'roberta', \n",
                "    'seyonec/PubChem10M_SMILES_BPE_450k', \n",
                "    num_labels=2,\n",
                "    args=model_args,\n",
                "    use_cuda=True  # Will use Colab GPU\n",
                ")\n",
                "\n",
                "model.train_model(train_df)\n",
                "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 5: Upload to Hugging Face\n",
                "# REPLACE 'tajo9128' WITH YOUR USERNAME\n",
                "repo_name = \"biodockify-ai-alzheimers\"\n",
                "\n",
                "# Save locally first\n",
                "model.save_model(repo_name)\n",
                "\n",
                "# Upload\n",
                "from huggingface_hub import HfApi\n",
                "api = HfApi()\n",
                "api.upload_folder(\n",
                "    folder_path=repo_name,\n",
                "    repo_id=f\"tajo9128/{repo_name}\",\n",
                "    repo_type=\"model\"\n",
                ")\n",
                "print(f\"Uploaded to https://huggingface.co/tajo9128/{repo_name}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}